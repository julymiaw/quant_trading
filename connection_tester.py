#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“å’ŒTushare APIè¿æ¥æµ‹è¯•å·¥å…·
æ–‡ä»¶å: connection_tester.py
è™šæ‹Ÿç¯å¢ƒ: quant_trading
Pythonç‰ˆæœ¬: 3.10.x (æ¨è)

è¯¥è„šæœ¬ç”¨äºæµ‹è¯•MySQLæ•°æ®åº“è¿æ¥å’ŒTushare API tokenæ˜¯å¦æœ‰æ•ˆï¼Œ
å¹¶ç”Ÿæˆè¯¦ç»†çš„APIå¯ç”¨æ€§æŠ¥å‘Šï¼Œå¸®åŠ©å¼€å‘è€…äº†è§£å½“å‰å¯ä»¥è®¿é—®å“ªäº›åŠŸèƒ½ã€‚
"""

import pymysql
import json
import os
import logging
from datetime import datetime
import time
import argparse

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é»˜è®¤è®¾ç½® - è¿™äº›é€šå¸¸ä¸éœ€è¦ä¿®æ”¹
DB_DEFAULTS = {
    "host": "localhost",
    "port": 3306,
    "user": "root",
    "database": "quantitative_trading",
    "charset": "utf8mb4"
}

# Tushare APIåˆ†ç±»åŠå¯¹åº”çš„åŠŸèƒ½
TUSHARE_API_CATEGORIES = {
    "è‚¡ç¥¨æ•°æ®": [
        {"api": "stock_basic", "name": "è‚¡ç¥¨åˆ—è¡¨", "points": 120},
        {"api": "daily", "name": "æ—¥çº¿è¡Œæƒ…", "points": 120},
        {"api": "weekly", "name": "å‘¨çº¿è¡Œæƒ…", "points": 2000},
        {"api": "monthly", "name": "æœˆçº¿è¡Œæƒ…", "points": 2000},
        {"api": "daily_basic", "name": "æ¯æ—¥æŒ‡æ ‡æ•°æ®", "points": 2000},
        {"api": "new_share", "name": "IPOæ–°è‚¡åˆ—è¡¨", "points": 120},
        {"api": "top_list", "name": "é¾™è™æ¦œæ¯æ—¥æ˜ç»†", "points": 2000},
        {"api": "top_inst", "name": "é¾™è™æ¦œæœºæ„äº¤æ˜“æ˜ç»†", "points": 2000},
        {"api": "pledge_detail", "name": "è‚¡æƒè´¨æŠ¼æ˜ç»†", "points": 2000},
        {"api": "pledge_stat", "name": "è‚¡æƒè´¨æŠ¼ç»Ÿè®¡", "points": 2000},
        {"api": "margin", "name": "èèµ„èåˆ¸äº¤æ˜“æ±‡æ€»", "points": 2000},
        {"api": "margin_detail", "name": "èèµ„èåˆ¸äº¤æ˜“æ˜ç»†", "points": 2000},
        {"api": "repurchase", "name": "è‚¡ç¥¨å›è´­", "points": 2000},
        {"api": "concept", "name": "æ¦‚å¿µè‚¡è¡Œæƒ…", "points": 5000},
        {"api": "concept_detail", "name": "æ¦‚å¿µè‚¡åˆ—è¡¨", "points": 5000},
        {"api": "share_float", "name": "é™å”®è‚¡è§£ç¦", "points": 3000},
        {"api": "block_trade", "name": "å¤§å®—äº¤æ˜“", "points": 2000},
        {"api": "stk_holdernumber", "name": "è‚¡ä¸œäººæ•°", "points": 2000},
        {"api": "moneyflow", "name": "ä¸ªè‚¡èµ„é‡‘æµå‘", "points": 2000},
        {"api": "stk_holdertrade", "name": "è‚¡ä¸œå¢å‡æŒ", "points": 2000},
        {"api": "stk_limit", "name": "æ¯æ—¥æ¶¨è·Œåœä»·æ ¼", "points": 2000},
        {"api": "hk_hold", "name": "æ²ªæ·±è‚¡é€šæŒè‚¡æ˜ç»†", "points": 2000}
    ],
    "è´¢åŠ¡æ•°æ®": [
        {"api": "income", "name": "åˆ©æ¶¦è¡¨", "points": 2000},
        {"api": "balancesheet", "name": "èµ„äº§è´Ÿå€ºè¡¨", "points": 2000},
        {"api": "cashflow", "name": "ç°é‡‘æµé‡è¡¨", "points": 2000},
        {"api": "forecast", "name": "ä¸šç»©é¢„å‘Š", "points": 2000},
        {"api": "express", "name": "ä¸šç»©å¿«æŠ¥", "points": 2000},
        {"api": "dividend", "name": "åˆ†çº¢é€è‚¡", "points": 2000},
        {"api": "fina_indicator", "name": "è´¢åŠ¡æŒ‡æ ‡æ•°æ®", "points": 2000},
        {"api": "fina_audit", "name": "è´¢åŠ¡å®¡è®¡æ„è§", "points": 2000},
        {"api": "fina_mainbz", "name": "ä¸»è¥ä¸šåŠ¡æ„æˆ", "points": 2000},
        {"api": "disclosure_date", "name": "è´¢æŠ¥æŠ«éœ²è®¡åˆ’", "points": 2000}
    ],
    "åŸºé‡‘æ•°æ®": [
        {"api": "fund_basic", "name": "å…¬å‹ŸåŸºé‡‘åˆ—è¡¨", "points": 2000},
        {"api": "fund_company", "name": "å…¬å‹ŸåŸºé‡‘å…¬å¸", "points": 2000},
        {"api": "fund_nav", "name": "å…¬å‹ŸåŸºé‡‘å‡€å€¼", "points": 2000},
        {"api": "fund_daily", "name": "åœºå†…åŸºé‡‘æ—¥çº¿è¡Œæƒ…", "points": 2000},
        {"api": "fund_div", "name": "å…¬å‹ŸåŸºé‡‘åˆ†çº¢", "points": 2000},
        {"api": "fund_portfolio", "name": "å…¬å‹ŸåŸºé‡‘æŒä»“æ•°æ®", "points": 2000},
        {"api": "fund_adj", "name": "åŸºé‡‘å¤æƒå› å­", "points": 5000}
    ],
    "æœŸè´§æ•°æ®": [
        {"api": "fut_basic", "name": "æœŸè´§åˆçº¦åˆ—è¡¨", "points": 2000},
        {"api": "trade_cal", "name": "æœŸè´§äº¤æ˜“æ—¥å†", "points": 2000},
        {"api": "fut_daily", "name": "æœŸè´§æ—¥çº¿è¡Œæƒ…", "points": 2000},
        {"api": "fut_holding", "name": "æ¯æ—¥æˆäº¤æŒä»“æ’å", "points": 2000},
        {"api": "fut_wsr", "name": "ä»“å•æ—¥æŠ¥", "points": 2000},
        {"api": "fut_settle", "name": "ç»“ç®—å‚æ•°", "points": 2000},
        {"api": "index_daily", "name": "å—åæœŸè´§æŒ‡æ•°è¡Œæƒ…", "points": 2000}
    ],
    "æœŸæƒæ•°æ®": [
        {"api": "opt_basic", "name": "æœŸæƒåˆçº¦åˆ—è¡¨", "points": 2000},
        {"api": "opt_daily", "name": "æœŸæƒæ—¥çº¿è¡Œæƒ…", "points": 5000}
    ],
    "å€ºåˆ¸æ•°æ®": [
        {"api": "cb_basic", "name": "å¯è½¬å€ºåŸºç¡€ä¿¡æ¯", "points": 2000},
        {"api": "cb_issue", "name": "å¯è½¬å€ºå‘è¡Œæ•°æ®", "points": 2000},
        {"api": "cb_daily", "name": "å¯è½¬å€ºæ—¥çº¿æ•°æ®", "points": 2000}
    ],
    "å¤–æ±‡æ•°æ®": [
        {"api": "fx_obasic", "name": "å¤–æ±‡åŸºç¡€ä¿¡æ¯ï¼ˆæµ·å¤–ï¼‰", "points": 2000},
        {"api": "fx_daily", "name": "å¤–æ±‡æ—¥çº¿è¡Œæƒ…", "points": 2000}
    ],
    "æŒ‡æ•°æ•°æ®": [
        {"api": "index_basic", "name": "æŒ‡æ•°åŸºæœ¬ä¿¡æ¯", "points": 2000},
        {"api": "index_daily", "name": "æŒ‡æ•°æ—¥çº¿è¡Œæƒ…", "points": 2000},
        {"api": "index_weekly", "name": "æŒ‡æ•°å‘¨çº¿è¡Œæƒ…", "points": 2000},
        {"api": "index_monthly", "name": "æŒ‡æ•°æœˆçº¿è¡Œæƒ…", "points": 2000},
        {"api": "index_weight", "name": "æŒ‡æ•°æˆåˆ†å’Œæƒé‡", "points": 2000},
        {"api": "index_dailybasic", "name": "å¤§ç›˜æŒ‡æ•°æ¯æ—¥æŒ‡æ ‡", "points": 4000},
        {"api": "index_classify", "name": "ç”³ä¸‡è¡Œä¸šåˆ†ç±»", "points": 2000},
        {"api": "index_member_all", "name": "ç”³ä¸‡è¡Œä¸šæˆåˆ†", "points": 2000}
    ],
    "æ¸¯è‚¡æ•°æ®": [
        {"api": "hk_basic", "name": "æ¸¯è‚¡åˆ—è¡¨", "points": 2000},
        {"api": "hk_daily", "name": "æ¸¯è‚¡æ—¥çº¿è¡Œæƒ…", "points": 1000},
        {"api": "hk_mins", "name": "æ¸¯è‚¡åˆ†é’Ÿè¡Œæƒ…", "points": 2000}
    ],
    "å®è§‚ç»æµ": [
        {"api": "shibor", "name": "SHIBORåˆ©ç‡æ•°æ®", "points": 2000},
        {"api": "shibor_quote", "name": "SHIBORæŠ¥ä»·æ•°æ®", "points": 2000},
        {"api": "shibor_lpr", "name": "LPRè´·æ¬¾åŸºç¡€åˆ©ç‡", "points": 120},
        {"api": "libor", "name": "LIBORæ‹†å€Ÿåˆ©ç‡", "points": 120},
        {"api": "hibor", "name": "HIBORæ‹†å€Ÿåˆ©ç‡", "points": 120},
        {"api": "wz_index", "name": "æ¸©å·æ°‘é—´å€Ÿè´·åˆ©ç‡", "points": 2000},
        {"api": "gz_index", "name": "å¹¿å·æ°‘é—´å€Ÿè´·åˆ©ç‡", "points": 2000}
    ],
    "è¡Œä¸šç‰¹è‰²": [
        {"api": "tmt_twincome", "name": "å°æ¹¾ç”µå­äº§ä¸šæœˆè¥æ”¶", "points": 0},
        {"api": "tmt_twincomedetail", "name": "å°æ¹¾ç”µå­äº§ä¸šæœˆè¥æ”¶æ˜ç»†", "points": 0},
        {"api": "bo_monthly", "name": "ç”µå½±æœˆåº¦ç¥¨æˆ¿", "points": 500},
        {"api": "bo_weekly", "name": "ç”µå½±å‘¨åº¦ç¥¨æˆ¿", "points": 500},
        {"api": "bo_daily", "name": "ç”µå½±æ—¥åº¦ç¥¨æˆ¿", "points": 500},
        {"api": "bo_cinema", "name": "å½±é™¢æ¯æ—¥ç¥¨æˆ¿", "points": 500},
        {"api": "film_record", "name": "å…¨å›½ç”µå½±å‰§æœ¬å¤‡æ¡ˆæ•°æ®", "points": 120},
        {"api": "teleplay_record", "name": "å…¨å›½ç”µè§†å‰§æœ¬å¤‡æ¡ˆæ•°æ®", "points": 600}
    ]
}


class ConnectionTester:
    """æ•°æ®åº“å’ŒAPIè¿æ¥æµ‹è¯•ç±»"""

    def __init__(self, config_file: str = "config.json"):
        """åˆå§‹åŒ–è¿æ¥æµ‹è¯•å™¨"""
        self.config_file = config_file
        self.config = None
        self.connection = None
        self.api_test_results = {}
        self.api_success = False
        self.db_success = False

    def create_sample_config(self):
        """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
        sample_config = {
            "db_password": "your_mysql_password_here",
            "tushare_token": "your_tushare_token_here"
        }

        with open(self.config_file, "w", encoding="utf-8") as f:
            json.dump(sample_config, f, indent=4, ensure_ascii=False)

        print(f"âœ… å·²åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶: {self.config_file}")
        print("ğŸ“ è¯·ç¼–è¾‘æ­¤æ–‡ä»¶ï¼Œå¡«å…¥æ­£ç¡®çš„æ•°æ®åº“å¯†ç å’ŒTushare token")

    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            if not os.path.exists(self.config_file):
                print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
                print("æ­£åœ¨åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶...")
                self.create_sample_config()
                return False

            with open(self.config_file, "r", encoding="utf-8") as f:
                self.config = json.load(f)

            # éªŒè¯é…ç½®å®Œæ•´æ€§
            required_keys = ["db_password", "tushare_token"]
            for key in required_keys:
                if key not in self.config:
                    raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„å­—æ®µ: {key}")

            # æ£€æŸ¥æ˜¯å¦è¿˜æ˜¯é»˜è®¤å€¼
            if self.config["db_password"] == "your_mysql_password_here":
                print("âš ï¸  è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„MySQLå¯†ç ")
                return False

            if self.config["tushare_token"] == "your_tushare_token_here":
                print("âš ï¸  è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„Tushare token")
                return False

            logger.info("é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def test_database_connection(self):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        if not self.config:
            logger.error("é…ç½®æœªåŠ è½½ï¼Œæ— æ³•æµ‹è¯•æ•°æ®åº“è¿æ¥")
            return False
    
        logger.info("è¿æ¥æ•°æ®åº“...")
                
        try:
            self.connection = pymysql.connect(
                host=DB_DEFAULTS["host"],
                port=DB_DEFAULTS["port"],
                user=DB_DEFAULTS["user"],
                password=self.config["db_password"],
                database=DB_DEFAULTS["database"],
                charset=DB_DEFAULTS["charset"],
                autocommit=False
            )
            
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            self.db_success = True
            return True
            
        except Exception as e:
            self.db_success = False
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False

    def test_tushare_api(self):
        """æµ‹è¯•Tushare APIåŠå¯ç”¨åŠŸèƒ½"""
        if not self.config:
            logger.error("é…ç½®æœªåŠ è½½ï¼Œæ— æ³•æµ‹è¯•Tushare API")
            return False

        logger.info("å¼€å§‹æµ‹è¯•Tushare APIè¿æ¥")

        try:
            import tushare as ts
            ts.set_token(self.config["tushare_token"])
            pro = ts.pro_api()

            logger.info("å¼€å§‹æµ‹è¯•APIåŠŸèƒ½å¯ç”¨æ€§...")
            self._test_api_categories(pro)
                
            self.api_success = True
            return True

        except Exception as e:
            logger.error(f"Tushare APIæµ‹è¯•å¤±è´¥: {e}")
            self.api_success = False
            return False
            
    def _test_api_categories(self, pro):
        """æµ‹è¯•ä¸åŒç±»åˆ«çš„APIåŠŸèƒ½"""
        total_apis = 0
        available_apis = 0
        
        for category, apis in TUSHARE_API_CATEGORIES.items():
            category_results = []
            
            logger.info(f"æµ‹è¯• {category} ç±»åˆ«ä¸‹çš„API...")
                
            for api_info in apis:
                api_func = api_info["api"]
                api_name = api_info["name"]
                api_points = api_info["points"]
                total_apis += 1
                
                # é€šè¿‡å®é™…è°ƒç”¨æµ‹è¯•APIå¯ç”¨æ€§
                try:
                    # é€šç”¨å‚æ•°ï¼šä»…è·å–ä¸€æ¡è®°å½•
                    kwargs = {"limit": 1}
                    
                    # ç‰¹æ®ŠAPIçš„å¤„ç†
                    if api_func == "trade_cal":
                        kwargs = {"start_date": "20200101", "end_date": "20200110"}
                    elif api_func == "daily":
                        kwargs = {"ts_code": "000001.SZ", "start_date": "20200101", "end_date": "20200105"}
                    elif api_func == "weekly" or api_func == "monthly":
                        kwargs = {"ts_code": "000001.SZ", "start_date": "20200101", "end_date": "20200630"}
                    elif api_func == "income" or api_func == "balancesheet" or api_func == "cashflow":
                        kwargs = {"ts_code": "000001.SZ", "period": "20191231"}
                        
                    # è°ƒç”¨API
                    result = getattr(pro, api_func)(**kwargs)
                    
                    if result is not None and not result.empty:
                        status = "å¯ç”¨"
                        call_status = True
                        available_apis += 1
                    else:
                        status = "è¿”å›ç©ºæ•°æ®"
                        call_status = False
                except Exception as e:
                    status = f"é”™è¯¯: {str(e)[:50]}..."
                    call_status = False
                
                # æ·»åŠ åˆ°ç»“æœ
                category_results.append({
                    "api": api_func,
                    "name": api_name,
                    "points_required": api_points,
                    "status": status,
                    "call_status": call_status
                })
                
                # é™åˆ¶APIè°ƒç”¨é¢‘ç‡ï¼Œé¿å…è¶…è¿‡é™åˆ¶
                time.sleep(0.3)
            
            # ä¿å­˜ç±»åˆ«ç»“æœ
            self.api_test_results[category] = category_results
            
        logger.info(f"APIæµ‹è¯•å®Œæˆï¼Œå…±æµ‹è¯• {total_apis} ä¸ªAPIï¼Œå…¶ä¸­ {available_apis} ä¸ªå¯ç”¨")

    def generate_api_report(self, output_dir="api_reports", report_format="json"):
        """ç”ŸæˆAPIå¯ç”¨æ€§æŠ¥å‘Šå¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶å¤¹"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        report_file = f"{output_dir}/tushare_api_report_{timestamp}.{report_format}"
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "report_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "token_status": "æœ‰æ•ˆ" if self.api_success else "æ— æ•ˆ",
            "database_status": "è¿æ¥æˆåŠŸ" if self.db_success else "è¿æ¥å¤±è´¥",
            "api_summary": {
                "total_categories": len(self.api_test_results),
                "total_apis": sum(len(apis) for apis in self.api_test_results.values()),
                "available_apis": sum(
                    sum(1 for api in apis if api["call_status"]) 
                    for apis in self.api_test_results.values()
                )
            },
            "api_categories": {}
        }
        
        # å¡«å……APIæµ‹è¯•ç»“æœ
        for category, apis in self.api_test_results.items():
            available_count = sum(1 for api in apis if api["call_status"])
            
            report["api_categories"][category] = {
                "name": category,
                "total_apis": len(apis),
                "available_apis": available_count,
                "apis": apis
            }
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
            
        print(f"\nâœ… APIå¯ç”¨æ€§æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        return report_file
        
    def generate_text_summary(self):
        """ç”Ÿæˆç®€æ˜çš„æ–‡æœ¬æ‘˜è¦"""
        if not self.api_test_results:
            return "æœªæ‰§è¡ŒAPIæµ‹è¯•"
            
        total_apis = sum(len(apis) for apis in self.api_test_results.values())
        available_apis = sum(
            sum(1 for api in apis if api["call_status"]) 
            for apis in self.api_test_results.values()
        )
        
        summary = [
            "=" * 60,
            "Tushare API å¯ç”¨æ€§æ‘˜è¦",
            "=" * 60,
            f"APIæ€»æ•°: {total_apis}",
            f"å¯ç”¨API: {available_apis} ({available_apis/total_apis*100:.1f}%)",
            "-" * 60,
            "APIç±»åˆ«æ‘˜è¦:",
        ]
        
        for category, apis in self.api_test_results.items():
            available_count = sum(1 for api in apis if api["call_status"])
            summary.append(f"  {category}: {available_count}/{len(apis)} å¯ç”¨")
            
        summary.append("=" * 60)
        return "\n".join(summary)

    def run_full_test(self, generate_report=True, report_dir="api_reports"):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        logger.info("å¼€å§‹è¿è¡Œè¿æ¥æµ‹è¯•å·¥å…·")

        # 1. åŠ è½½é…ç½®
        if not self.load_config():
            return False

        # 2. æµ‹è¯•æ•°æ®åº“è¿æ¥
        db_success = self.test_database_connection()

        # 3. æµ‹è¯•Tushare API
        api_success = self.test_tushare_api()

        # 4. æ€»ç»“
        logger.info(f"æµ‹è¯•ç»“æœæ€»ç»“ - æ•°æ®åº“è¿æ¥: {'æˆåŠŸ' if db_success else 'å¤±è´¥'}, Tushare API: {'æˆåŠŸ' if api_success else 'å¤±è´¥'}")

        # 5. ç”ŸæˆAPIæŠ¥å‘Š
        if generate_report and self.api_test_results:
            report_file = self.generate_api_report(report_dir)
            print(self.generate_text_summary())

        return db_success and api_success

    def close_connection(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="æ•°æ®åº“å’ŒTushare APIè¿æ¥æµ‹è¯•å·¥å…·")
    parser.add_argument("--config", "-c", type=str, default="config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--report-dir", "-d", type=str, default="api_reports", help="æŠ¥å‘Šè¾“å‡ºç›®å½•")
    parser.add_argument("--no-report", action="store_true", help="ä¸ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶")
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = ConnectionTester(args.config)

    try:
        # è¿è¡Œæµ‹è¯•
        tester.run_full_test(
            generate_report=not args.no_report,
            report_dir=args.report_dir
        )

    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­äº†æµ‹è¯•")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        tester.close_connection()


if __name__ == "__main__":
    main()