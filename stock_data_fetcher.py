#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - è‚¡ç¥¨æ•°æ®è·å–è„šæœ¬
æ–‡ä»¶å: stock_data_fetcher.py
è™šæ‹Ÿç¯å¢ƒ: quant_trading
Pythonç‰ˆæœ¬: 3.10.x (æ¨è)

ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†æ•æ„Ÿä¿¡æ¯ï¼Œæ”¯æŒå®‰å…¨çš„è‚¡ç¥¨æ•°æ®è·å–å’Œæ•°æ®åº“æ“ä½œ
å¢å¼ºåŠŸèƒ½: å›æµ‹æ•°æ®å‡†å¤‡ä¸å®Œæ•´æ€§æ£€æŸ¥
"""

import tushare as ts
import pymysql
import pandas as pd
import numpy as np
import json
import os
import time  # æ·»åŠ timeæ¨¡å—ç”¨äºAPIè°ƒç”¨é—´éš”
from datetime import datetime, timedelta, date
import logging
import uuid
import traceback
from typing import List, Dict, Any, Optional, Tuple, Set
from pathlib import Path
import argparse  # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ


class ConfigManager:
    """é…ç½®ç®¡ç†ç±»"""

    @staticmethod
    def load_config(config_file: str = "config.json") -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_file):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")

        with open(config_file, "r", encoding="utf-8") as f:
            config = json.load(f)

        # éªŒè¯å¿…éœ€é…ç½®
        required_sections = ["database", "tushare"]
        for section in required_sections:
            if section not in config:
                raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„section: {section}")

        # æ·»åŠ å›æµ‹é…ç½®çš„é»˜è®¤å€¼
        if "backtest" not in config:
            config["backtest"] = {
                "min_history_days": 365,  # è‡³å°‘1å¹´æ•°æ®
                "preferred_history_days": 1095,  # å»ºè®®3å¹´æ•°æ®
                "batch_query_interval": 1,  # APIè°ƒç”¨é—´éš”(ç§’)
                "data_check_threshold": 0.9,  # æ•°æ®å®Œæ•´æ€§é˜ˆå€¼(90%)
            }

        return config


class StockDataManager:
    """è‚¡ç¥¨æ•°æ®ç®¡ç†ç±»"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–è‚¡ç¥¨æ•°æ®ç®¡ç†å™¨

        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.connection = None

        # é…ç½®æ—¥å¿—çº§åˆ«
        log_level = config.get("system", {}).get("log_level", "INFO")
        logging.basicConfig(
            level=getattr(logging, log_level),
            format="%(asctime)s - %(levelname)s - %(message)s",
        )
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–Tushare
        ts.set_token(config["tushare"]["token"])
        self.pro = ts.pro_api()

    def connect_database(self):
        """è¿æ¥æ•°æ®åº“ï¼Œå°è¯•å¤šç§è®¤è¯æ–¹å¼"""
        db_config = self.config["database"]

        # è·å–é»˜è®¤è½¬æ¢å™¨å¹¶è¿›è¡Œè‡ªå®šä¹‰
        conv = pymysql.converters.conversions.copy()
        conv[datetime.date] = pymysql.converters.escape_date

        # æ·»åŠ è‡ªå®šä¹‰çš„æ•°å€¼ç±»å‹è½¬æ¢
        conv[pymysql.FIELD_TYPE.DECIMAL] = float
        conv[pymysql.FIELD_TYPE.NEWDECIMAL] = float

        # å°è¯•å¤šç§è¿æ¥æ–¹å¼
        connection_methods = [
            {
                "name": "æ ‡å‡†è¿æ¥",
                "params": {
                    "host": db_config["host"],
                    "port": db_config.get("port", 3306),
                    "user": db_config["user"],
                    "password": db_config["password"],
                    "database": db_config["database"],
                    "charset": db_config.get("charset", "utf8mb4"),
                    "autocommit": False,
                    # ä½¿ç”¨å®Œæ•´çš„è½¬æ¢å™¨é…ç½®
                    "conv": conv,
                },
            },
            {
                "name": "å…¼å®¹æ¨¡å¼è¿æ¥",
                "params": {
                    "host": db_config["host"],
                    "port": db_config.get("port", 3306),
                    "user": db_config["user"],
                    "password": db_config["password"],
                    "database": db_config["database"],
                    "charset": db_config.get("charset", "utf8mb4"),
                    "autocommit": False,
                    "auth_plugin_map": {
                        "caching_sha2_password": "mysql_native_password"
                    },
                    "ssl_disabled": True,
                    # ä½¿ç”¨å®Œæ•´çš„è½¬æ¢å™¨é…ç½®
                    "conv": conv,
                },
            },
            {
                "name": "å¼ºåˆ¶åŸç”Ÿè®¤è¯",
                "params": {
                    "host": db_config["host"],
                    "port": db_config.get("port", 3306),
                    "user": db_config["user"],
                    "password": db_config["password"],
                    "database": db_config["database"],
                    "charset": db_config.get("charset", "utf8mb4"),
                    "autocommit": False,
                    "auth_plugin_map": {
                        "caching_sha2_password": "mysql_native_password",
                        "sha256_password": "mysql_native_password",
                    },
                    "ssl_disabled": True,
                    "local_infile": True,
                    # ä½¿ç”¨å®Œæ•´çš„è½¬æ¢å™¨é…ç½®
                    "conv": conv,
                },
            },
        ]

        for method in connection_methods:
            try:
                self.logger.info(f"å°è¯•{method['name']}...")
                self.connection = pymysql.connect(**method["params"])
                self.logger.info(f"{method['name']}æˆåŠŸ")
                return
            except Exception as e:
                self.logger.warning(f"{method['name']}å¤±è´¥: {e}")
                continue

        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
        raise Exception("æ‰€æœ‰æ•°æ®åº“è¿æ¥æ–¹å¼éƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®åº“çŠ¶æ€")

    def close_database(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            self.logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def get_stock_data(
        self,
        ts_codes: List[str] = None,
        start_date: str = None,
        end_date: str = None,
        trade_date: str = None,
    ) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨è¡Œæƒ…æ•°æ®"""
        try:
            if trade_date:
                self.logger.info(f"è·å–{trade_date}çš„å…¨éƒ¨è‚¡ç¥¨æ•°æ®")
                df = self.pro.daily(trade_date=trade_date)
            elif ts_codes:
                ts_code_str = ",".join(ts_codes)
                self.logger.info(
                    f"è·å–è‚¡ç¥¨{ts_code_str}ä»{start_date}åˆ°{end_date}çš„æ•°æ®"
                )
                df = self.pro.daily(
                    ts_code=ts_code_str, start_date=start_date, end_date=end_date
                )
            else:
                raise ValueError("å¿…é¡»æŒ‡å®šts_codesæˆ–trade_dateå‚æ•°")

            if df.empty:
                self.logger.warning("æœªè·å–åˆ°è‚¡ç¥¨æ•°æ®")
                return pd.DataFrame()

            self.logger.info(f"æˆåŠŸè·å–{len(df)}æ¡è‚¡ç¥¨æ•°æ®")
            return df

        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            raise

    def process_stock_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†è‚¡ç¥¨æ•°æ®ï¼Œè½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼"""
        if df.empty:
            return df

        # é‡å‘½ååˆ—
        column_mapping = {
            "ts_code": "stock_code",
            "trade_date": "trade_date",
            "open": "open_price",
            "high": "high_price",
            "low": "low_price",
            "close": "close_price",
            "pre_close": "pre_close_price",
            "change": "change_amount",
            "pct_chg": "change_percent",
            "vol": "volume",
            "amount": "amount",
        }

        processed_df = df.rename(columns=column_mapping)

        # æ•°æ®ç±»å‹è½¬æ¢
        processed_df["trade_date"] = pd.to_datetime(processed_df["trade_date"]).dt.date
        processed_df["change_percent"] = processed_df["change_percent"] / 100
        processed_df["volume"] = processed_df["volume"] * 100
        processed_df["amount"] = processed_df["amount"] * 1000

        # æ·»åŠ å…ƒæ•°æ®
        processed_df["data_source"] = "tushare"
        processed_df["collect_time"] = datetime.now()

        # å¤„ç†ç¼ºå¤±å€¼
        processed_df = processed_df.fillna(0)

        # é€‰æ‹©éœ€è¦çš„åˆ—
        required_columns = [
            "stock_code",
            "trade_date",
            "open_price",
            "high_price",
            "low_price",
            "close_price",
            "pre_close_price",
            "change_amount",
            "change_percent",
            "volume",
            "amount",
            "data_source",
            "collect_time",
        ]

        processed_df = processed_df[required_columns]
        self.logger.info(f"æ•°æ®å¤„ç†å®Œæˆï¼Œå¤„ç†äº†{len(processed_df)}æ¡è®°å½•")
        return processed_df

    def insert_stock_data(self, df: pd.DataFrame) -> int:
        """æ‰¹é‡æ’å…¥è‚¡ç¥¨æ•°æ®"""
        if df.empty:
            self.logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦æ’å…¥")
            return 0

        try:
            cursor = self.connection.cursor()

            insert_sql = """
            INSERT INTO StockMarketData (
                stock_code, trade_date, open_price, high_price, low_price,
                close_price, pre_close_price, change_amount, change_percent,
                volume, amount, data_source, collect_time
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
            ) ON DUPLICATE KEY UPDATE
                open_price = VALUES(open_price),
                high_price = VALUES(high_price),
                low_price = VALUES(low_price),
                close_price = VALUES(close_price),
                pre_close_price = VALUES(pre_close_price),
                change_amount = VALUES(change_amount),
                change_percent = VALUES(change_percent),
                volume = VALUES(volume),
                amount = VALUES(amount),
                collect_time = VALUES(collect_time)
            """

            # æ‰¹é‡å¤„ç†æ•°æ®
            batch_size = self.config.get("system", {}).get("batch_size", 1000)
            total_inserted = 0

            for i in range(0, len(df), batch_size):
                batch_df = df.iloc[i : i + batch_size]
                data_list = [tuple(row) for _, row in batch_df.iterrows()]

                cursor.executemany(insert_sql, data_list)
                batch_inserted = cursor.rowcount
                total_inserted += batch_inserted

                self.logger.info(
                    f"æ‰¹æ¬¡ {i//batch_size + 1}: æ’å…¥{batch_inserted}æ¡è®°å½•"
                )

            self.connection.commit()
            self.logger.info(f"æ€»è®¡æˆåŠŸæ’å…¥/æ›´æ–°{total_inserted}æ¡è‚¡ç¥¨æ•°æ®")
            return total_inserted

        except Exception as e:
            if self.connection:
                self.connection.rollback()
            self.logger.error(f"æ’å…¥è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            raise
        finally:
            if cursor:
                cursor.close()

    def get_latest_stock_prices(self, stock_codes: List[str] = None) -> pd.DataFrame:
        """é€šè¿‡LatestStockPriceè§†å›¾è·å–æœ€æ–°è‚¡ä»·"""
        try:
            cursor = self.connection.cursor()

            if stock_codes:
                placeholders = ",".join(["%s"] * len(stock_codes))
                query_sql = f"""
                SELECT stock_code, latest_date, latest_price, 
                       change_percent, volume
                FROM LatestStockPrice 
                WHERE stock_code IN ({placeholders})
                ORDER BY stock_code
                """
                cursor.execute(query_sql, stock_codes)
            else:
                query_sql = """
                SELECT stock_code, latest_date, latest_price, 
                       change_percent, volume
                FROM LatestStockPrice 
                ORDER BY change_percent DESC
                LIMIT 50
                """
                cursor.execute(query_sql)

            results = cursor.fetchall()

            if not results:
                self.logger.warning("æœªæŸ¥è¯¢åˆ°æœ€æ–°è‚¡ä»·æ•°æ®")
                return pd.DataFrame()

            columns = ["è‚¡ç¥¨ä»£ç ", "æœ€æ–°æ—¥æœŸ", "æœ€æ–°ä»·æ ¼", "æ¶¨è·Œå¹…(%)", "æˆäº¤é‡"]
            df = pd.DataFrame(results, columns=columns)

            # å¤„ç†DECIMALç±»å‹æ•°æ®ï¼Œè½¬æ¢ä¸ºfloat
            df["æ¶¨è·Œå¹…(%)"] = pd.to_numeric(df["æ¶¨è·Œå¹…(%)"], errors="coerce") * 100
            df["æœ€æ–°ä»·æ ¼"] = pd.to_numeric(df["æœ€æ–°ä»·æ ¼"], errors="coerce")
            df["æˆäº¤é‡"] = pd.to_numeric(df["æˆäº¤é‡"], errors="coerce").astype("Int64")

            # æ ¼å¼åŒ–æ˜¾ç¤º
            df["æ¶¨è·Œå¹…(%)"] = df["æ¶¨è·Œå¹…(%)"].round(2)
            df["æœ€æ–°ä»·æ ¼"] = df["æœ€æ–°ä»·æ ¼"].round(3)

            self.logger.info(f"æŸ¥è¯¢åˆ°{len(df)}åªè‚¡ç¥¨çš„æœ€æ–°ä»·æ ¼")
            return df

        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢æœ€æ–°è‚¡ä»·å¤±è´¥: {e}")
            raise
        finally:
            if cursor:
                cursor.close()

    # ========== ä»¥ä¸‹ä¸ºæ–°å¢çš„å›æµ‹æ•°æ®å‡†å¤‡ç›¸å…³å‡½æ•° ==========

    def get_stock_list(self, list_status="L") -> List[str]:
        """
        è·å–è‚¡ç¥¨åˆ—è¡¨

        Args:
            list_status: ä¸Šå¸‚çŠ¶æ€ L(ä¸Šå¸‚)ã€D(é€€å¸‚)ã€P(æš‚åœä¸Šå¸‚)ï¼Œé»˜è®¤L

        Returns:
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        try:
            df = self.pro.stock_basic(
                exchange="",
                list_status=list_status,
                fields="ts_code,symbol,name,area,industry,list_date",
            )
            if df.empty:
                self.logger.warning(f"æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
                return []

            stock_list = df["ts_code"].tolist()
            self.logger.info(f"æˆåŠŸè·å–{len(stock_list)}åªè‚¡ç¥¨ä¿¡æ¯")
            return stock_list
        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def get_available_trade_dates(self, start_date: str, end_date: str) -> List[str]:
        """
        è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„äº¤æ˜“æ—¥

        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)

        Returns:
            äº¤æ˜“æ—¥åˆ—è¡¨
        """
        try:
            df = self.pro.trade_cal(
                exchange="SSE", start_date=start_date, end_date=end_date, is_open=1
            )
            if df.empty:
                self.logger.warning(f"æœªè·å–åˆ°{start_date}è‡³{end_date}çš„äº¤æ˜“æ—¥ä¿¡æ¯")
                return []

            trade_dates = df["cal_date"].tolist()
            self.logger.info(f"æˆåŠŸè·å–{len(trade_dates)}ä¸ªäº¤æ˜“æ—¥")
            return trade_dates
        except Exception as e:
            self.logger.error(f"è·å–äº¤æ˜“æ—¥å¤±è´¥: {e}")
            return []

    def check_stock_data_completeness(
        self, stock_code: str, start_date: str, end_date: str
    ) -> Tuple[float, int, int]:
        """
        æ£€æŸ¥æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ•°æ®å®Œæ•´æ€§

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)

        Returns:
            (å®Œæ•´æ€§æ¯”ç‡, ç°æœ‰äº¤æ˜“æ—¥æ•°, åº”æœ‰äº¤æ˜“æ—¥æ•°)
        """
        try:
            cursor = self.connection.cursor()

            # å°†æ—¥æœŸè½¬æ¢ä¸ºtushareæ ¼å¼
            start_date_ts = start_date.replace("-", "")
            end_date_ts = end_date.replace("-", "")

            # è·å–è¯¥æ—¶é—´æ®µå†…åº”æœ‰çš„äº¤æ˜“æ—¥
            trade_dates = self.get_available_trade_dates(start_date_ts, end_date_ts)
            expected_days = len(trade_dates)

            if expected_days == 0:
                return 0.0, 0, 0

            # æŸ¥è¯¢å®é™…æœ‰æ•°æ®çš„äº¤æ˜“æ—¥
            query = """
            SELECT COUNT(DISTINCT trade_date) 
            FROM StockMarketData 
            WHERE stock_code = %s 
            AND trade_date BETWEEN %s AND %s
            """
            cursor.execute(query, (stock_code, start_date, end_date))
            actual_days = cursor.fetchone()[0]

            # è®¡ç®—å®Œæ•´æ€§æ¯”ç‡
            completeness_ratio = (
                actual_days / expected_days if expected_days > 0 else 0.0
            )

            return completeness_ratio, actual_days, expected_days

        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å¤±è´¥: {e}")
            return 0.0, 0, 0
        finally:
            if cursor:
                cursor.close()

    def get_data_date_range(
        self, stock_code: str
    ) -> Tuple[Optional[date], Optional[date]]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æ•°æ®åº“ä¸­çš„æ—¥æœŸèŒƒå›´

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 

        Returns:
            (æœ€æ—©æ—¥æœŸ, æœ€æ™šæ—¥æœŸ)ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›(None, None)
        """
        try:
            cursor = self.connection.cursor()

            query = """
            SELECT MIN(trade_date), MAX(trade_date)
            FROM StockMarketData 
            WHERE stock_code = %s
            """
            cursor.execute(query, (stock_code,))
            result = cursor.fetchone()

            if not result or result[0] is None:
                return None, None

            return result[0], result[1]

        except Exception as e:
            self.logger.error(f"è·å–æ•°æ®æ—¥æœŸèŒƒå›´å¤±è´¥: {e}")
            return None, None
        finally:
            if cursor:
                cursor.close()

    def prepare_backtest_data(
        self, stock_codes: List[str], end_date: str = None, history_days: int = None
    ) -> Dict[str, Any]:
        """
        å‡†å¤‡å›æµ‹æ‰€éœ€çš„å†å²æ•°æ®

        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸ
            history_days: éœ€è¦çš„å†å²æ•°æ®å¤©æ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„preferred_history_days

        Returns:
            å‡†å¤‡ç»“æœçš„ç»Ÿè®¡ä¿¡æ¯
        """
        if not end_date:
            end_date = datetime.now().strftime("%Y-%m-%d")

        if not history_days:
            history_days = self.config.get("backtest", {}).get(
                "preferred_history_days", 1095
            )

        start_date = (
            datetime.strptime(end_date, "%Y-%m-%d") - timedelta(days=history_days)
        ).strftime("%Y-%m-%d")

        # è½¬æ¢ä¸ºtushareæ ¼å¼
        start_date_ts = start_date.replace("-", "")
        end_date_ts = end_date.replace("-", "")

        self.logger.info(f"å‡†å¤‡ä»{start_date}åˆ°{end_date}çš„å›æµ‹æ•°æ®")

        # æ‰¹å¤„ç†è‚¡ç¥¨æ•°æ®è·å–
        batch_size = 5  # Tushare APIæœ‰é¢‘ç‡é™åˆ¶ï¼Œæ¯æ¬¡è·å–å°‘é‡è‚¡ç¥¨
        api_interval = self.config.get("backtest", {}).get("batch_query_interval", 1)
        data_check_threshold = self.config.get("backtest", {}).get(
            "data_check_threshold", 0.9
        )

        result_stats = {
            "total_stocks": len(stock_codes),
            "processed_stocks": 0,
            "added_data_points": 0,
            "failed_stocks": [],
            "success_stocks": [],
            "start_date": start_date,
            "end_date": end_date,
            "history_days": history_days,
        }

        # è·å–äº¤æ˜“æ—¥å†
        trade_dates = self.get_available_trade_dates(start_date_ts, end_date_ts)
        expected_days = len(trade_dates)
        result_stats["expected_trading_days"] = expected_days

        self.logger.info(f"è¯¥æ—¶é—´æ®µå†…åº”æœ‰{expected_days}ä¸ªäº¤æ˜“æ—¥")

        for i in range(0, len(stock_codes), batch_size):
            batch_stocks = stock_codes[i : i + batch_size]
            self.logger.info(
                f"å¤„ç†ç¬¬{i//batch_size + 1}æ‰¹ï¼Œè‚¡ç¥¨: {', '.join(batch_stocks)}"
            )

            for stock in batch_stocks:
                try:
                    # æ£€æŸ¥ç°æœ‰æ•°æ®å®Œæ•´æ€§
                    completeness, actual_days, _ = self.check_stock_data_completeness(
                        stock, start_date, end_date
                    )

                    if completeness >= data_check_threshold:
                        self.logger.info(
                            f"è‚¡ç¥¨{stock}æ•°æ®å®Œæ•´æ€§è‰¯å¥½({completeness:.2%})ï¼Œæ— éœ€æ›´æ–°"
                        )
                        result_stats["success_stocks"].append(stock)
                        result_stats["processed_stocks"] += 1
                        continue

                    # è·å–æ•°æ®å¹¶å¤„ç†
                    self.logger.info(
                        f"è·å–è‚¡ç¥¨{stock}çš„å†å²æ•°æ®ï¼Œå®Œæ•´æ€§: {completeness:.2%}ï¼Œå½“å‰æ•°æ®: {actual_days}å¤©"
                    )
                    raw_data = self.get_stock_data(
                        ts_codes=[stock], start_date=start_date_ts, end_date=end_date_ts
                    )

                    if raw_data.empty:
                        self.logger.warning(
                            f"æœªè·å–åˆ°è‚¡ç¥¨{stock}çš„æ•°æ®ï¼Œå¯èƒ½æ˜¯æ–°ä¸Šå¸‚æˆ–å·²é€€å¸‚"
                        )
                        result_stats["failed_stocks"].append(stock)
                        continue

                    processed_data = self.process_stock_data(raw_data)
                    inserted_count = self.insert_stock_data(processed_data)

                    # æ›´æ–°ç»Ÿè®¡
                    result_stats["added_data_points"] += inserted_count
                    result_stats["processed_stocks"] += 1
                    result_stats["success_stocks"].append(stock)

                    # æ£€æŸ¥æ›´æ–°åçš„å®Œæ•´æ€§
                    new_completeness, new_actual_days, _ = (
                        self.check_stock_data_completeness(stock, start_date, end_date)
                    )
                    self.logger.info(
                        f"è‚¡ç¥¨{stock}æ•°æ®æ›´æ–°å®Œæˆï¼Œæ–°å®Œæ•´æ€§: {new_completeness:.2%}ï¼Œå½“å‰æ•°æ®: {new_actual_days}å¤©"
                    )

                except Exception as e:
                    self.logger.error(f"å¤„ç†è‚¡ç¥¨{stock}å¤±è´¥: {e}")
                    result_stats["failed_stocks"].append(stock)

                # æ·»åŠ APIè°ƒç”¨é—´éš”ï¼Œé¿å…è¶…è¿‡é¢‘ç‡é™åˆ¶
                time.sleep(api_interval)

            # æ¯æ‰¹å¤„ç†å®Œæ˜¾ç¤ºè¿›åº¦
            progress = min(100, int((i + len(batch_stocks)) / len(stock_codes) * 100))
            self.logger.info(
                f"æ•°æ®å‡†å¤‡è¿›åº¦: {progress}% ({i + len(batch_stocks)}/{len(stock_codes)})"
            )

        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡æ•°æ®
        result_stats["success_rate"] = (
            len(result_stats["success_stocks"]) / result_stats["total_stocks"]
            if result_stats["total_stocks"] > 0
            else 0
        )

        return result_stats

    def get_backtest_ready_stocks(
        self,
        min_completeness: float = 0.95,
        start_date: str = None,
        end_date: str = None,
    ) -> List[str]:
        """
        è·å–å¯ç”¨äºå›æµ‹çš„è‚¡ç¥¨åˆ—è¡¨(æ•°æ®å®Œæ•´æ€§è¾¾æ ‡)

        Args:
            min_completeness: æœ€ä½æ•°æ®å®Œæ•´æ€§è¦æ±‚
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)

        Returns:
            å¯ç”¨äºå›æµ‹çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        if not end_date:
            end_date = datetime.now().strftime("%Y-%m-%d")

        if not start_date:
            # é»˜è®¤å–é…ç½®ä¸­çš„æœ€å°å†å²å¤©æ•°
            min_days = self.config.get("backtest", {}).get("min_history_days", 365)
            start_date = (
                datetime.strptime(end_date, "%Y-%m-%d") - timedelta(days=min_days)
            ).strftime("%Y-%m-%d")

        try:
            cursor = self.connection.cursor()

            # è·å–æœ‰æ•°æ®çš„æ‰€æœ‰è‚¡ç¥¨
            query = """
            SELECT DISTINCT stock_code
            FROM StockMarketData
            """
            cursor.execute(query)
            all_stocks = [row[0] for row in cursor.fetchall()]

            if not all_stocks:
                self.logger.warning("æ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨æ•°æ®")
                return []

            ready_stocks = []
            total = len(all_stocks)

            self.logger.info(
                f"æ£€æŸ¥{total}åªè‚¡ç¥¨åœ¨{start_date}è‡³{end_date}æœŸé—´çš„æ•°æ®å®Œæ•´æ€§"
            )

            # æ£€æŸ¥æ¯åªè‚¡ç¥¨çš„æ•°æ®å®Œæ•´æ€§
            for i, stock in enumerate(all_stocks):
                completeness, actual, expected = self.check_stock_data_completeness(
                    stock, start_date, end_date
                )

                if completeness >= min_completeness:
                    ready_stocks.append(stock)

                # æ¯100åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if (i + 1) % 100 == 0 or i + 1 == total:
                    self.logger.info(
                        f"è¿›åº¦: {i+1}/{total} ({(i+1)/total:.1%}), å¯ç”¨: {len(ready_stocks)}"
                    )

            self.logger.info(f"æ£€æŸ¥å®Œæˆï¼Œæœ‰{len(ready_stocks)}/{total}åªè‚¡ç¥¨å¯ç”¨äºå›æµ‹")
            return ready_stocks

        except Exception as e:
            self.logger.error(f"è·å–å¯å›æµ‹è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
        finally:
            if cursor:
                cursor.close()

    def get_index_data(
        self, index_code: str, start_date: str, end_date: str
    ) -> pd.DataFrame:
        """
        è·å–æŒ‡æ•°æ•°æ®ï¼ˆå¯¹å›æµ‹ä¹Ÿå¾ˆé‡è¦ï¼‰

        Args:
            index_code: æŒ‡æ•°ä»£ç ï¼Œå¦‚000001.SHï¼ˆä¸Šè¯æŒ‡æ•°ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)

        Returns:
            æŒ‡æ•°æ•°æ®DataFrame
        """
        try:
            self.logger.info(f"è·å–æŒ‡æ•°{index_code}ä»{start_date}åˆ°{end_date}çš„æ•°æ®")
            df = self.pro.index_daily(
                ts_code=index_code, start_date=start_date, end_date=end_date
            )

            if df.empty:
                self.logger.warning(f"æœªè·å–åˆ°æŒ‡æ•°{index_code}çš„æ•°æ®")
                return pd.DataFrame()

            self.logger.info(f"æˆåŠŸè·å–{len(df)}æ¡æŒ‡æ•°æ•°æ®")
            return df

        except Exception as e:
            self.logger.error(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - è‚¡ç¥¨æ•°æ®è·å–è„šæœ¬")
    print("æ–‡ä»¶å: stock_data_fetcher.py")
    print("è™šæ‹Ÿç¯å¢ƒ: quant_trading")
    print("æ¨èPythonç‰ˆæœ¬: 3.10.x")
    print("=" * 60)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="é‡åŒ–äº¤æ˜“ç³»ç»Ÿè‚¡ç¥¨æ•°æ®è·å–å·¥å…·")
    parser.add_argument("--market", action="store_true", help="è·å–å…¨å¸‚åœºæ•°æ®")
    parser.add_argument("--backtest", action="store_true", help="å‡†å¤‡å›æµ‹æ•°æ®")
    parser.add_argument("--stocks", type=str, help="æŒ‡å®šè‚¡ç¥¨ä»£ç ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”")
    parser.add_argument("--days", type=int, help="å†å²æ•°æ®å¤©æ•°")
    parser.add_argument("--end", type=str, help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥å“ªäº›è‚¡ç¥¨å¯ç”¨äºå›æµ‹")
    parser.add_argument(
        "--completeness", type=float, default=0.95, help="æ•°æ®å®Œæ•´æ€§é˜ˆå€¼"
    )
    args = parser.parse_args()

    try:
        # 1. åŠ è½½é…ç½®
        print("ğŸ“„ åŠ è½½é…ç½®æ–‡ä»¶...")
        config = ConfigManager.load_config("config.json")
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")

        # 2. åˆ›å»ºæ•°æ®ç®¡ç†å™¨
        stock_manager = StockDataManager(config)

        # 3. è¿æ¥æ•°æ®åº“
        print("ğŸ”Œ è¿æ¥æ•°æ®åº“...")
        stock_manager.connect_database()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")

        # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ‰§è¡Œç›¸åº”åŠŸèƒ½
        if args.backtest:
            # å‡†å¤‡å›æµ‹æ•°æ®
            if args.stocks:
                stock_codes = args.stocks.split(",")
            else:
                # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤è‚¡ç¥¨
                stock_codes = config.get("trading", {}).get(
                    "default_stocks",
                    [
                        "000001.SZ",
                        "000002.SZ",
                        "600000.SH",
                        "600036.SH",
                        "600519.SH",
                        "000858.SZ",
                    ],
                )

            print(f"\nğŸ“Š å‡†å¤‡å›æµ‹æ•°æ®:")
            print(f"  è‚¡ç¥¨åˆ—è¡¨: {', '.join(stock_codes)}")

            # å‡†å¤‡æ•°æ®
            results = stock_manager.prepare_backtest_data(
                stock_codes=stock_codes, end_date=args.end, history_days=args.days
            )

            # æ˜¾ç¤ºç»“æœ
            print("\nğŸ“ˆ å›æµ‹æ•°æ®å‡†å¤‡ç»“æœ:")
            print(f"  æ•°æ®èŒƒå›´: {results['start_date']} è‡³ {results['end_date']}")
            print(f"  äº¤æ˜“æ—¥æ•°: {results['expected_trading_days']}")
            print(
                f"  å¤„ç†è‚¡ç¥¨: {results['processed_stocks']}/{results['total_stocks']}"
            )
            print(f"  æ·»åŠ æ•°æ®ç‚¹: {results['added_data_points']}")
            print(f"  æˆåŠŸç‡: {results['success_rate']:.2%}")

            if results["failed_stocks"]:
                print(f"  å¤±è´¥è‚¡ç¥¨: {', '.join(results['failed_stocks'])}")

        elif args.check:
            # æ£€æŸ¥å¯ç”¨äºå›æµ‹çš„è‚¡ç¥¨
            end_date = args.end or datetime.now().strftime("%Y-%m-%d")

            if args.days:
                start_date = (
                    datetime.strptime(end_date, "%Y-%m-%d") - timedelta(days=args.days)
                ).strftime("%Y-%m-%d")
            else:
                # ä½¿ç”¨é…ç½®çš„æœ€å°å¤©æ•°
                min_days = config.get("backtest", {}).get("min_history_days", 365)
                start_date = (
                    datetime.strptime(end_date, "%Y-%m-%d") - timedelta(days=min_days)
                ).strftime("%Y-%m-%d")

            print(f"\nğŸ” æ£€æŸ¥å¯ç”¨äºå›æµ‹çš„è‚¡ç¥¨:")
            print(f"  æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
            print(f"  å®Œæ•´æ€§è¦æ±‚: {args.completeness:.2%}")

            # è·å–å¯ç”¨è‚¡ç¥¨
            ready_stocks = stock_manager.get_backtest_ready_stocks(
                min_completeness=args.completeness,
                start_date=start_date,
                end_date=end_date,
            )

            if ready_stocks:
                print(f"\nâœ… æ‰¾åˆ°{len(ready_stocks)}åªå¯ç”¨äºå›æµ‹çš„è‚¡ç¥¨")

                # å¦‚æœå°‘äº10åªï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰
                if len(ready_stocks) <= 10:
                    print(f"  å¯ç”¨è‚¡ç¥¨: {', '.join(ready_stocks)}")
                else:
                    # å¦åˆ™åªæ˜¾ç¤ºå‰10åª
                    print(f"  éƒ¨åˆ†å¯ç”¨è‚¡ç¥¨: {', '.join(ready_stocks[:10])}...")

                # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                result_file = (
                    f"backtest_ready_stocks_{datetime.now().strftime('%Y%m%d')}.txt"
                )
                with open(result_file, "w") as f:
                    f.write("\n".join(ready_stocks))
                print(f"  å®Œæ•´åˆ—è¡¨å·²ä¿å­˜è‡³: {result_file}")
            else:
                print(f"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")

        elif args.market:
            # è·å–å…¨å¸‚åœºæ•°æ®
            get_today_market_data()

        else:
            # é»˜è®¤æµç¨‹
            # 4. è·å–é…ç½®çš„è‚¡ç¥¨å’Œæ—¥æœŸèŒƒå›´
            stock_codes = config.get("trading", {}).get(
                "default_stocks",
                [
                    "000001.SZ",
                    "000002.SZ",
                    "600000.SH",
                    "600036.SH",
                    "600519.SH",
                    "000858.SZ",
                ],
            )

            days_back = config.get("trading", {}).get("data_days_back", 30)
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days_back)

            start_date_str = start_date.strftime("%Y%m%d")
            end_date_str = end_date.strftime("%Y%m%d")

            print(f"ğŸ“ˆ è·å–è‚¡ç¥¨: {', '.join(stock_codes)}")
            print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date_str} - {end_date_str}")

            # 5. è·å–å¹¶å¤„ç†æ•°æ®
            print("ğŸ”„ è·å–è‚¡ç¥¨æ•°æ®...")
            raw_data = stock_manager.get_stock_data(
                ts_codes=stock_codes, start_date=start_date_str, end_date=end_date_str
            )

            if raw_data.empty:
                print("âŒ æœªè·å–åˆ°è‚¡ç¥¨æ•°æ®")
                return

            print("ğŸ”„ å¤„ç†æ•°æ®æ ¼å¼...")
            processed_data = stock_manager.process_stock_data(raw_data)

            print("ğŸ’¾ å†™å…¥æ•°æ®åº“...")
            inserted_count = stock_manager.insert_stock_data(processed_data)
            print(f"âœ… æˆåŠŸå¤„ç†{inserted_count}æ¡æ•°æ®")

            # 6. æŸ¥è¯¢æœ€æ–°è‚¡ä»·
            print("ğŸ“Š æŸ¥è¯¢æœ€æ–°è‚¡ä»·...")
            latest_prices = stock_manager.get_latest_stock_prices(stock_codes)

            if not latest_prices.empty:
                print("\n" + "=" * 80)
                print("ğŸ“ˆ æœ€æ–°è‚¡ä»·ä¿¡æ¯ï¼ˆé€šè¿‡LatestStockPriceè§†å›¾æŸ¥è¯¢ï¼‰")
                print("=" * 80)
                print(latest_prices.to_string(index=False))
                print("=" * 80)

                # æ•°æ®åˆ†æ
                print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
                print(f"   æ€»è®¡è‚¡ç¥¨æ•°é‡: {len(latest_prices)}")
                print(f"   å¹³å‡æ¶¨è·Œå¹…: {latest_prices['æ¶¨è·Œå¹…(%)'].mean():.2f}%")
                print(f"   æœ€å¤§æ¶¨å¹…: {latest_prices['æ¶¨è·Œå¹…(%)'].max():.2f}%")
                print(f"   æœ€å¤§è·Œå¹…: {latest_prices['æ¶¨è·Œå¹…(%)'].min():.2f}%")

                up_stocks = len(latest_prices[latest_prices["æ¶¨è·Œå¹…(%)"] > 0])
                down_stocks = len(latest_prices[latest_prices["æ¶¨è·Œå¹…(%)"] < 0])
                flat_stocks = len(latest_prices[latest_prices["æ¶¨è·Œå¹…(%)"] == 0])

                print(f"   ğŸ“ˆ ä¸Šæ¶¨è‚¡ç¥¨: {up_stocks} åª")
                print(f"   ğŸ“‰ ä¸‹è·Œè‚¡ç¥¨: {down_stocks} åª")
                print(f"   â– å¹³ç›˜è‚¡ç¥¨: {flat_stocks} åª")

                # æ‰¾å‡ºæ¶¨è·Œå¹…æœ€å¤§çš„è‚¡ç¥¨
                if len(latest_prices) > 0:
                    top_gainer = latest_prices.loc[latest_prices["æ¶¨è·Œå¹…(%)"].idxmax()]
                    top_loser = latest_prices.loc[latest_prices["æ¶¨è·Œå¹…(%)"].idxmin()]

                    print(f"\nğŸ† ä»Šæ—¥è¡¨ç°:")
                    print(
                        f"   æœ€å¤§æ¶¨å¹…: {top_gainer['è‚¡ç¥¨ä»£ç ']} ({top_gainer['æ¶¨è·Œå¹…(%)']}%)"
                    )
                    print(
                        f"   æœ€å¤§è·Œå¹…: {top_loser['è‚¡ç¥¨ä»£ç ']} ({top_loser['æ¶¨è·Œå¹…(%)']}%)"
                    )
            else:
                print("âŒ æœªæŸ¥è¯¢åˆ°æœ€æ–°è‚¡ä»·æ•°æ®")

        print("\nğŸ‰ è‚¡ç¥¨æ•°æ®è·å–å’Œå¤„ç†æµç¨‹å®Œæˆï¼")

    except FileNotFoundError as e:
        print(f"âŒ é…ç½®æ–‡ä»¶é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·è¿è¡Œ python test_database_connection.py ç”Ÿæˆé…ç½®æ–‡ä»¶")
    except Exception as e:
        error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"
        print(f"âŒ {error_msg}")
        logging.error(traceback.format_exc())

    finally:
        if "stock_manager" in locals():
            stock_manager.close_database()


def get_today_market_data():
    """è·å–ä»Šæ—¥å¸‚åœºæ•°æ®çš„ä¾¿æ·å‡½æ•°"""
    try:
        config = ConfigManager.load_config("config.json")
        stock_manager = StockDataManager(config)

        # è·å–æ˜¨æ—¥æ•°æ®ï¼ˆä»Šæ—¥æ•°æ®å¯èƒ½æœªæ›´æ–°ï¼‰
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")

        stock_manager.connect_database()

        print(f"ğŸ“… è·å–{yesterday}å…¨å¸‚åœºæ•°æ®...")
        raw_data = stock_manager.get_stock_data(trade_date=yesterday)

        if not raw_data.empty:
            processed_data = stock_manager.process_stock_data(raw_data)
            inserted_count = stock_manager.insert_stock_data(processed_data)

            print(f"âœ… æˆåŠŸè·å–å¹¶æ’å…¥{inserted_count}æ¡å…¨å¸‚åœºæ•°æ®")

            # æ˜¾ç¤ºå¸‚åœºæ¦‚å†µ
            latest_all = stock_manager.get_latest_stock_prices()
            if not latest_all.empty:
                print(f"\nğŸ“Š å¸‚åœºæ¦‚å†µ:")
                print(f"   æ€»è‚¡ç¥¨æ•°: {len(latest_all)}")
                print(f"   å¹³å‡æ¶¨è·Œå¹…: {latest_all['æ¶¨è·Œå¹…(%)'].mean():.2f}%")

                # æ¶¨è·Œåˆ†å¸ƒ
                up_count = len(latest_all[latest_all["æ¶¨è·Œå¹…(%)"] > 0])
                down_count = len(latest_all[latest_all["æ¶¨è·Œå¹…(%)"] < 0])

                print(f"   ä¸Šæ¶¨å®¶æ•°: {up_count} ({up_count/len(latest_all)*100:.1f}%)")
                print(
                    f"   ä¸‹è·Œå®¶æ•°: {down_count} ({down_count/len(latest_all)*100:.1f}%)"
                )
        else:
            print(f"âŒ æœªè·å–åˆ°{yesterday}çš„å¸‚åœºæ•°æ®")

    except Exception as e:
        print(f"âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
    finally:
        if "stock_manager" in locals():
            stock_manager.close_database()


def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
    print(
        """
ğŸ“– ä½¿ç”¨è¯´æ˜:

1ï¸âƒ£ é¦–æ¬¡ä½¿ç”¨:
   python test_database_connection.py  # æµ‹è¯•è¿æ¥å¹¶ç”Ÿæˆé…ç½®æ–‡ä»¶

2ï¸âƒ£ è·å–æŒ‡å®šè‚¡ç¥¨æ•°æ®:
   python stock_data_fetcher.py  # è·å–é»˜è®¤è‚¡ç¥¨æœ€è¿‘30å¤©æ•°æ®

3ï¸âƒ£ è·å–å…¨å¸‚åœºæ•°æ®:
   python stock_data_fetcher.py --market  # è·å–æ˜¨æ—¥å…¨å¸‚åœºæ•°æ®

4ï¸âƒ£ å‡†å¤‡å›æµ‹æ•°æ®:
   python stock_data_fetcher.py --backtest  # å‡†å¤‡é»˜è®¤è‚¡ç¥¨çš„å›æµ‹æ•°æ®
   python stock_data_fetcher.py --backtest --stocks 000001.SZ,600000.SH --days 1095  # å‡†å¤‡æŒ‡å®šè‚¡ç¥¨3å¹´æ•°æ®
   python stock_data_fetcher.py --backtest --end 2024-08-31  # æŒ‡å®šç»“æŸæ—¥æœŸ

5ï¸âƒ£ æ£€æŸ¥å›æµ‹å¯ç”¨è‚¡ç¥¨:
   python stock_data_fetcher.py --check  # æ£€æŸ¥å“ªäº›è‚¡ç¥¨å¯ç”¨äºå›æµ‹
   python stock_data_fetcher.py --check --days 730 --completeness 0.98  # æ£€æŸ¥2å¹´å†…æ•°æ®å®Œæ•´æ€§>98%çš„è‚¡ç¥¨

ğŸ“‹ å‚æ•°è¯´æ˜:
   --market           : è·å–å…¨å¸‚åœºæ•°æ®
   --backtest         : å‡†å¤‡å›æµ‹æ•°æ®
   --stocks [codes]   : æŒ‡å®šè‚¡ç¥¨ä»£ç ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”
   --days [number]    : å†å²æ•°æ®å¤©æ•°
   --end [date]       : ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
   --check            : æ£€æŸ¥å“ªäº›è‚¡ç¥¨å¯ç”¨äºå›æµ‹
   --completeness [n] : æ•°æ®å®Œæ•´æ€§é˜ˆå€¼(0-1)

âš ï¸ æ³¨æ„äº‹é¡¹:
   - è¯·ç¡®ä¿config.jsonåœ¨.gitignoreä¸­ï¼Œé¿å…æäº¤æ•æ„Ÿä¿¡æ¯
   - Tushare APIæœ‰è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·åˆç†ä½¿ç”¨
   - å›æµ‹æ•°æ®å»ºè®®è‡³å°‘å‡†å¤‡1å¹´ä»¥ä¸Šæ•°æ®
   - å»ºè®®åœ¨éäº¤æ˜“æ—¶é—´è·å–æ•°æ®ï¼Œé¿å…å½±å“å®æ—¶åˆ†æ
    """
    )


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and (sys.argv[1] == "--help" or sys.argv[1] == "-h"):
        show_usage()
    else:
        # ä½¿ç”¨argparseå¤„ç†å‚æ•°
        main()
